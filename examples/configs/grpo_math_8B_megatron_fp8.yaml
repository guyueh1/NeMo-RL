# GRPO Algorithm Configuration
defaults: "grpo_math_8B_megatron.yaml"

loss_fn:
  use_importance_sampling_correction: true

policy:
  generation:
    vllm_cfg:
      precision: 'fp8'
      use_deep_gemm: true
  vllm_kwargs:
    compilation_config:
      pass_config:
        enable_fusion: true
  megatron_cfg:
    tensor_model_parallel_size: 1
    fp8_cfg:
      enabled: true
      fp8: "hybrid"
      fp8_recipe: "blockwise"
      fp8_param: true
    optimizer:
      use_precision_aware_optimizer: false
    distributed_data_parallel_config:
      grad_reduce_in_fp32: true
      overlap_param_gather: true