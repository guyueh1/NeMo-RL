# GRPO Algorithm Configuration
defaults: "grpo_math_8B_megatron.yaml"

loss_fn:
  use_importance_sampling_correction: true

policy:
  generation:
    vllm_cfg:
      precision: 'fp8'
      use_deep_gemm: true
      gpu_memory_utilization: 0.5
    vllm_kwargs:
      compilation_config:
        pass_config:
          enable_fusion: true
          enable_noop: true
  sequence_packing:
    sequence_length_round: 16
  megatron_cfg:
    fp8_cfg:
      enabled: true
      fp8: "hybrid"
      fp8_recipe: "blockwise"
      fp8_param: true
    optimizer:
      use_precision_aware_optimizer: false
    env_vars:
      NVTE_FP8_BLOCK_SCALING_FP32_SCALES: "1"